# Common School Archive of New York State
## Multimodal Digital Archive Pipeline

**Project Status:** Active Development / Processing Phase  
**Last Updated:** December 19, 2024

This repository contains the processing pipeline, raw assets, and development environment for the **Common School Archive**, a digital humanities initiative to preserve and analyze 19th-century New York State educational records.

The system employs a **multimodal AI pipeline** (using Qwen VL Plus) to transcribe, classify, and extract metadata from complex historical artifacts (handwritten ledgers, typed reports, mixed-media cards), preparing them for publication in an **Omeka Classic** digital exhibit.

---

## ðŸ“‚ Repository Architecture

### 1. Raw Assets (`raw/`)
The primary archival material, categorized by format:
- **`raw/imgs/`**: 210+ loose artifact photos (JPEG), processed as individual "items."
- **`raw/scans/`**: High-resolution PDF scans organized by collection:
  - **Kheel Center**: Published reports (e.g., *Toward Better Schools*).
  - **NYS Archives**: Archival series (A4456, B0494, B0594, A4645) containing rolls, consolidation data, and notecards.

### 2. Processing Core (Root & `scripts/`)
Scripts that transform raw assets into digital objects:
- **`ocr.py`**: The central engine. Wraps the OpenRouter API to send images/PDF pages to **Qwen VL Plus** for context-aware OCR.
- **`process_archive.py`**: The unified batch orchestrator. 
  - **PDF Mode**: Processes `raw/scans/` (Kheel & NYS Archives).
  - **Image Mode**: Processes `raw/imgs/` by reading `csv/images_inventory.csv`.
- **`scripts/build_images_inventory.py`**: Ingestion script for `raw/imgs`. Handles deduplication (SHA256), session grouping (time-based), and generates the master inventory CSV.

### 3. Metadata & Intelligence (`csv/`, `output/`, `prompts/`)
- **`csv/images_inventory.csv`**: The master registry of loose images, generated by the inventory script.
- **`csv/LIST_common-schools.xlsx`**: Controlled vocabulary for school districts (used for entity linking).
- **`scripts/prepare_image_label_requests.py`**: Prepares batch LLM prompts to classify images (e.g., "letter", "report") before OCR.
- **`output/ocr/`**: The destination for AI-generated content:
  - `text/`: Raw transcriptions.
  - `metadata/`: JSON sidecars with confidence scores and structural data.
  - `reports/`: Batch processing summaries.

---

## ðŸš€ End-to-End Roadmap

### Phase 1: Ingestion & Inventory (Status: âœ… Complete)
- **Objective**: Catalog every file and establish provenance.
- **Action**: `scripts/build_images_inventory.py` scans `raw/imgs`, hashes files, and groups bursts of photos into "sessions" (logical items).
- **Result**: `csv/images_inventory.csv` serves as the source of truth for loose images.

### Phase 2: AI Processing & OCR (Status: ðŸ”„ In Progress)
- **Objective**: Extract text and structure from pixels.
- **Action**:
  - Run `process_archive.py` to handle the PDF backlogs (Kheel & NYS Archives) and loose images.
- **Methodology**:
  - Uses `ocr_config.yaml` to dynamically select prompts.
  - For loose images, it leverages the `item_type` in the inventory to pick the best prompt (e.g., "Handwritten" for letters).
  - Generates confidence scores to flag items for human review.

---

## ðŸ›  Usage Guide

### 1. Environment Setup
Ensure `.env` contains your `OPENROUTER_KEY`.
```bash
pip install -r requirements.txt
```

### 2. Processing the Archive
The `process_archive.py` script is the primary tool for OCR.

```bash
# Process everything (Kheel + NYS + Images)
python process_archive.py --collection all

# Process loose images only (based on inventory)
python process_archive.py --collection images

# Process specific scan collections
python process_archive.py --collection kheel
python process_archive.py --collection nys
```

### 3. Inventorying Images
To update the inventory after adding new photos to `raw/imgs`:
```bash
python scripts/build_images_inventory.py
```

---

## ðŸ“„ Canonical Data Model (Draft)

The pipeline targets this schema for final Omeka ingestion:

| Field | Description | Source |
|-------|-------------|--------|
| **Title** | Derived from content or filename | LLM / Inventory |
| **Identifier** | UUID or Archival Call Number | `source_series` + `id` |
| **Date** | ISO 8601 (YYYY-MM-DD) | Extracted from Text |
| **Description** | Summary of contents | LLM |
| **Transcription** | Full text content | OCR (Qwen VL Plus) |
| **Format** | Document Type (Ledger, Letter, Report) | Classifier |
| **Creator** | School District / Official Name | Entity Linking |
| **Source** | Physical location/collection | `provenance` |

---

## ðŸ“š Resources & Context
- **`CLAUDE.md`**: Detailed technical documentation for the OCR implementation and API interactions.
- **`docs/`**: Project background presentations and proposals.